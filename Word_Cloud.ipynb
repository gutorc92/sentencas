{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import codecs\n",
    "from settings import Settings\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords   \n",
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_docs():\n",
    "    s = Settings()\n",
    "    list_files = os.listdir(os.path.join(s.path, \"textos\"))\n",
    "    list_docs = [readText(x, s) for x in list_files]\n",
    "    return list_docs, list_files\n",
    "l_docs, l_files = read_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readText(file_name, s):\n",
    "        text = \"\"\n",
    "        with codecs.open(os.path.join(s.path, \"textos\", file_name), \"r\", \"UTF-8\") as handle:\n",
    "           for line in handle.readlines():\n",
    "               line = line.lower()\n",
    "               line = re.sub(\"[0-9]+\", \"\", line)\n",
    "               line = re.sub(\"[_]+\", \"\", line)\n",
    "               text += \" \" + line\n",
    "        line = re.sub(\"\\s+\", \" \", text)\n",
    "        return text\n",
    "\n",
    "def get_stop_words():\n",
    "    stop_words_direito = ['impressao','artigo','direita', 'processo','sentenca','documento','digitalmente','direito', 'juiz','nao','autos','lauda','margem']\n",
    "    stop_words_direito = stop_words_direito + stopwords.words(\"portuguese\")\n",
    "    return stop_words_direito\n",
    "\n",
    "def tdm(list_docs, list_files):\n",
    "    vectorizer = CountVectorizer(strip_accents=\"unicode\", max_df =0.8, stop_words=get_stop_words())\n",
    "    x1 = vectorizer.fit_transform(list_docs)\n",
    "    df = pd.DataFrame(x1.toarray().transpose(), index=vectorizer.get_feature_names())\n",
    "    df.columns = list_files\n",
    "    return df\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = tdm(l_docs, l_files)\n",
    "print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = p.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = word_count.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count2 = word_count/total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(background_color=\"white\", max_words=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc.generate_from_frequencies(word_count2.to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
